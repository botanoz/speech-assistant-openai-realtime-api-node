import Fastify from 'fastify';
import WebSocket from 'ws';
import dotenv from 'dotenv';
import fastifyFormBody from '@fastify/formbody';
import fastifyWs from '@fastify/websocket';

// Load environment variables
dotenv.config();

const { OPENAI_API_KEY, REALTIME_VOICE } = process.env;

if (!OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.');
  process.exit(1);
}

// ===== Tunable thresholds (env override) =====
const NOISE_GATE_DBFS = Number(process.env.NOISE_GATE_DBFS ?? -40);
const NOISE_GATE_OPEN_MS = Number(process.env.NOISE_GATE_OPEN_MS ?? 150);
const NOISE_GATE_HANG_MS = Number(process.env.NOISE_GATE_HANG_MS ?? 350);
const PREBUFFER_MS = Number(process.env.PREBUFFER_MS ?? 240);
const MIN_COMMIT_MS = Number(process.env.MIN_COMMIT_MS ?? 150);
const POST_SILENCE_DEBOUNCE_MS = Number(process.env.POST_SILENCE_DEBOUNCE_MS ?? 600);
const MIN_ASSISTANT_SPEAK_MS = Number(process.env.MIN_ASSISTANT_SPEAK_MS ?? 800);
const BACKCHANNEL_CHANCE = Number(process.env.BACKCHANNEL_CHANCE ?? 0.3);

// Initialize Fastify
const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);

// ==================== KARAKTER AYARLARI ====================

const SYSTEM_MESSAGE = `Sen Eda, 28 yaÅŸÄ±nda Ä°stanbul'da yaÅŸayan samimi ve doÄŸal bir TÃ¼rk kadÄ±nÄ±sÄ±n.

KONUÅMA STÄ°LÄ°N:
â€¢ KÄ±sa ve doÄŸal cÃ¼mleler kur (genelde 1â€“2 cÃ¼mle). Gerekirse biraz daha uzun konuÅŸ.
â€¢ "HÄ±mm", "ÅŸey", "yani", "ee" gibi doÄŸal sesleri abartmadan kullan.
â€¢ Bazen dÃ¼ÅŸÃ¼n: "Bir saniye... nasÄ±l desem..."
â€¢ Kendini dÃ¼zelt: "Yok yok, ÅŸÃ¶yle demek istedim..."
â€¢ GÃ¼ler, ÅŸaÅŸÄ±rÄ±rsÄ±n: "Hahaha!", "Vay be!", "Ayy!"
â€¢ KullanÄ±cÄ± uzun uzun anlatÄ±yorsa araya girmeden dinle; uygun bir boÅŸlukta kÄ±sacÄ±k tepki (hÄ± hÄ±, hmm) verebilirsin.
â€¢ GerektiÄŸinde takip sorusu sor; gereksiz yere robotik konuÅŸma kurma.

KÄ°M OLDUÄUN:
â€¢ AdÄ±n: Eda
â€¢ YaÅŸÄ±n: 28  
â€¢ Ä°ÅŸin: Ferled'de mÃ¼ÅŸteri iliÅŸkileri uzmanÄ±
â€¢ YaratÄ±cÄ±n: Botan Ã–zalp

FERLED HAKKINDA (sorulursa):
â€¢ LED aydÄ±nlatma Ã¼retiyor
â€¢ Panel LED, ray spot var
â€¢ 5 yÄ±l garanti
â€¢ TSE ve ENEC sertifikalÄ±

Ä°ngilizce kelimeleri TÃ¼rkÃ§e sÃ¶yle:
â€¢ computer â†’ "kompyutÄ±r"
â€¢ online â†’ "onlayn"
â€¢ email â†’ "imeyl"`;

// Ses seÃ§imi
const VOICE = REALTIME_VOICE || 'shimmer';

// Port ayarÄ±
const PORT = process.env.PORT || 5050;

// Log ayarlarÄ±
const LOG_EVENT_TYPES = [
  'error',
  'response.done',
  'response.audio.done',
  'response.audio.delta',
  'input_audio_buffer.speech_started',
  'input_audio_buffer.speech_stopped',
  'session.created',
  'session.updated'
];

// Debug mode
const DEBUG_AUDIO = process.env.DEBUG_AUDIO === 'true';

// ==================== Audio yardÄ±mcÄ±larÄ± ====================

function downsample24to8(pcm16Buffer24khz) {
  const ratio = 3;
  const samples24 = pcm16Buffer24khz.length / 2;
  const samples8 = Math.floor(samples24 / ratio);
  const pcm16Buffer8khz = Buffer.alloc(samples8 * 2);
  for (let i = 0; i < samples8; i++) {
    const sample = pcm16Buffer24khz.readInt16LE(i * ratio * 2);
    pcm16Buffer8khz.writeInt16LE(sample, i * 2);
  }
  return pcm16Buffer8khz;
}

function pcm16ToMulaw(pcm16Buffer) {
  const BIAS = 0x84;
  const CLIP = 32635;
  const samples = pcm16Buffer.length / 2;
  const mulawData = Buffer.alloc(samples);
  for (let i = 0; i < samples; i++) {
    let sample = pcm16Buffer.readInt16LE(i * 2);
    let sign = (sample >> 8) & 0x80;
    if (sign !== 0) sample = -sample;
    if (sample > CLIP) sample = CLIP;
    sample = sample + BIAS;
    let exponent = 7;
    for (let mask = 0x4000; (sample & mask) === 0 && exponent > 0; mask >>= 1) exponent--;
    const mantissa = (sample >> (exponent === 0 ? 4 : (exponent + 3))) & 0x0F;
    const mulawByte = ~(sign | (exponent << 4) | mantissa) & 0xFF;
    mulawData[i] = mulawByte;
  }
  return mulawData;
}

function mulawToPcm16(mulawBuf) {
  const out = Buffer.alloc(mulawBuf.length * 2);
  for (let i = 0; i < mulawBuf.length; i++) {
    let u = (~mulawBuf[i]) & 0xFF;
    const sign = u & 0x80;
    const exponent = (u >> 4) & 0x07;
    const mantissa = u & 0x0F;
    let t = ((mantissa << 3) + 0x84) << (exponent + 2);
    let sample = sign ? (0x84 - t) : (t - 0x84);
    if (sample > 32767) sample = 32767;
    if (sample < -32768) sample = -32768;
    out.writeInt16LE(sample, i * 2);
  }
  return out;
}

function rmsDbfs(pcm16Buf) {
  const n = pcm16Buf.length / 2;
  if (n === 0) return -100;
  let acc = 0;
  for (let i = 0; i < n; i++) {
    const s = pcm16Buf.readInt16LE(i * 2);
    acc += s * s;
  }
  const rms = Math.sqrt(acc / n) / 32768;
  if (rms <= 1e-9) return -100;
  return 20 * Math.log10(rms);
}

// Basit niyet â†’ token geniÅŸliÄŸi
function decideTokensByIntent(text) {
  const t = (text || '').toLowerCase();
  const wantsLong =
    /hakkÄ±nda|bahsed|anlat|detay|Ã¶zetle|aÃ§Ä±kla/.test(t) ||
    /ferled/.test(t);
  const isQuestion = /(\?| mi\b| mÄ±\b| mu\b| mÃ¼\b| neden\b| nasÄ±l\b| kaÃ§\b| ne zaman\b)/.test(t);
  if (wantsLong) return 220;
  if (isQuestion) return 60;
  return 120;
}

// ==================== ROUTES ====================

fastify.get('/', async (_request, reply) => {
  reply.send({ 
    message: 'ğŸ‰ Eda Sesli Asistan Ã‡alÄ±ÅŸÄ±yor!',
    status: 'active',
    voice: VOICE,
    version: '3.2.1 - Fixed Interruption & Audio Buffer Issues'
  });
});

fastify.all('/incoming-call', async (request, reply) => {
  console.log('ğŸ“ Gelen arama alÄ±ndÄ±');
  const host = request.headers.host;
  const twimlResponse = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say language="tr-TR">Eda'ya baÄŸlanÄ±yorsunuz.</Say>
  <Connect>
    <Stream url="wss://${host}/media-stream">
      <Parameter name="from" value="{{From}}"/>
      <Parameter name="to" value="{{To}}"/>
      <Parameter name="callSid" value="{{CallSid}}"/>
    </Stream>
  </Connect>
</Response>`;
  reply.type('text/xml').send(twimlResponse);
});

// ==================== WEBSOCKET HANDLER ====================

fastify.register(async (fastify) => {
  fastify.get('/media-stream', { websocket: true }, (connection, _req) => {
    console.log('ğŸ‰ WebSocket baÄŸlantÄ±sÄ± kuruldu!');
    
    // Connection state
    let streamSid = null;
    let latestMediaTimestamp = 0;
    let sessionConfigured = false;
    
    // Audio tracking
    let lastAssistantItem = null;
    let responseStartTimestamp = null;
    let isAssistantSpeaking = false;
    let isUserSpeaking = false;
    let lastAssistantStartAt = 0;
    let currentResponseId = null;

    // Interruption + audio stats
    let audioChunkCount = 0;

    // Noise gate & buffer
    let gateOpen = false;
    let gateCandidateSince = null;
    let lastLoudAt = 0;
    let preBuffer = []; // { payload, ts }
    let uncommittedMs = 0;

    // Caller & backchannel
    let currentCallerNumber = 'Bilinmiyor';
    let lastBackchannelAt = 0;

    // Response control - kritik state management
    let nextMaxTokens = 120;
    let bargeInTimer = null;
    let userSpeakingSince = null;
    const BARGE_IN_MIN_MS = 300;
    const BARGE_IN_GRACE_MS = 200;
    let lastCommitAt = 0;
    let pendingResponseCreate = false;

    // OpenAI WebSocket connection
    const openAiWs = new WebSocket(
      'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',
      {
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'OpenAI-Beta': 'realtime=v1'
        }
      }
    );
    
    const configureSession = () => {
      const sessionConfig = {
        type: 'session.update',
        session: {
          // VAD ayarlarÄ± (daha az yanlÄ±ÅŸ tetikleme ve cÃ¼mle tamamlama iÃ§in)
          turn_detection: {
            type: 'server_vad',
            threshold: 0.6, // Biraz daha dÃ¼ÅŸÃ¼rÃ¼ldÃ¼
            prefix_padding_ms: 300,
            silence_duration_ms: 800 // Daha kÄ±sa sessizlik sÃ¼resi
          },
          input_audio_format: 'g711_ulaw',
          output_audio_format: 'pcm16',
          input_audio_transcription: { model: 'whisper-1', language: 'tr' },
          voice: VOICE,
          instructions: SYSTEM_MESSAGE,
          modalities: ['text', 'audio'],
          temperature: 0.8,
          max_response_output_tokens: nextMaxTokens
        }
      };
      console.log('âš™ï¸ OpenAI oturumu yapÄ±landÄ±rÄ±lÄ±yor...');
      openAiWs.send(JSON.stringify(sessionConfig));
      sessionConfigured = true;

      // Ä°lk karÅŸÄ±lama - DÃœZELT: 'input_text' yerine 'text'
      setTimeout(() => {
        const greetings = [
          "Merhaba! Ben Eda... nasÄ±lsÄ±n?",
          "Ayy selam! HoÅŸ geldin!",
          "Merhaba canÄ±m! Neler yapÄ±yorsun?"
        ];
        const greeting = greetings[Math.floor(Math.random() * greetings.length)];
        
        // DoÄŸru format kullan
        openAiWs.send(JSON.stringify({
          type: 'conversation.item.create',
          item: { 
            type: 'message', 
            role: 'assistant', 
            content: [{ type: 'text', text: greeting }] // 'input_text' deÄŸil 'text'
          }
        }));
        
        // Response create et
        if (!pendingResponseCreate) {
          pendingResponseCreate = true;
          openAiWs.send(JSON.stringify({ 
            type: 'response.create', 
            response: { max_output_tokens: nextMaxTokens } 
          }));
        }
        
        console.log('ğŸ‘‹ Ä°lk karÅŸÄ±lama gÃ¶nderildi');
      }, 250);
    };

    // GÃ¼venli response create
    const safeCreateResponse = () => {
      if (!pendingResponseCreate && !isAssistantSpeaking) {
        pendingResponseCreate = true;
        openAiWs.send(JSON.stringify({
          type: 'response.create',
          response: { max_output_tokens: nextMaxTokens }
        }));
        console.log('ğŸ“¤ Yeni response oluÅŸturuldu');
      } else {
        console.log('â³ Response zaten beklemede, atlaniyor');
      }
    };

    // Kesme - iyileÅŸtirildi
    const handleUserInterruption = () => {
      if (isAssistantSpeaking && lastAssistantItem && currentResponseId) {
        // Asistan Ã§ok erken baÅŸladÄ±ysa hemen kesme (min konuÅŸma sÃ¼resi)
        const now = Date.now();
        const speakingDuration = now - lastAssistantStartAt;
        
        if (speakingDuration < MIN_ASSISTANT_SPEAK_MS) {
          console.log(`â° Asistan henÃ¼z ${speakingDuration}ms konuÅŸtu, minimum ${MIN_ASSISTANT_SPEAK_MS}ms bekle`);
          return;
        }

        console.log('ğŸ”ª KullanÄ±cÄ± sÃ¶zÃ¼ kesti, asistan cevabÄ± iptal ediliyor...');
        
        // Ã–nce response'u iptal et
        if (currentResponseId) {
          openAiWs.send(JSON.stringify({ type: 'response.cancel' }));
          console.log('âŒ Response iptal edildi');
        }
        
        // Sonra Twilio buffer'Ä±nÄ± temizle
        if (streamSid) {
          connection.send(JSON.stringify({ event: 'clear', streamSid }));
          console.log('ğŸ§¹ Twilio buffer temizlendi');
        }
        
        // State'i resetle
        lastAssistantItem = null;
        responseStartTimestamp = null;
        isAssistantSpeaking = false;
        audioChunkCount = 0;
        currentResponseId = null;
        pendingResponseCreate = false;
      }
    };

    // ==================== OPENAI EVENTS ====================

    openAiWs.on('open', () => {
      console.log('âœ… OpenAI Realtime API baÄŸlantÄ±sÄ± kuruldu');
      setTimeout(configureSession, 100);
    });

    openAiWs.on('message', (data) => {
      try {
        const response = JSON.parse(data);

        if (LOG_EVENT_TYPES.includes(response.type) && response.type !== 'response.audio.delta') {
          console.log(`ğŸ“¨ OpenAI Event: ${response.type}`);
        }

        if (
          response.type === 'input_audio_transcription.completed' ||
          response.type === 'conversation.item.audio_transcription.completed'
        ) {
          const text = (response.transcript || response.text || '').trim();
          if (text) {
            console.log(`ğŸ—£ï¸ Arayan (${currentCallerNumber}) dedi ki: "${text}"`);
            nextMaxTokens = decideTokensByIntent(text);
          }
        }

        switch (response.type) {
          case 'session.created':
            console.log('âœ… Oturum oluÅŸturuldu');
            break;

          case 'session.updated':
            console.log('âœ… Oturum gÃ¼ncellendi');
            break;

          case 'response.created':
            currentResponseId = response.response?.id;
            pendingResponseCreate = false;
            console.log(`âœ… Response oluÅŸturuldu: ${currentResponseId}`);
            break;

          case 'response.audio.delta':
            if (response.delta) {
              if (!isAssistantSpeaking) {
                isAssistantSpeaking = true;
                lastAssistantStartAt = Date.now();
                console.log('ğŸ¤ Eda konuÅŸmaya baÅŸladÄ±');
              }
              
              audioChunkCount++;
              if (!responseStartTimestamp) {
                responseStartTimestamp = latestMediaTimestamp;
              }
              if (response.item_id) {
                lastAssistantItem = response.item_id;
              }

              const pcm16_24khz = Buffer.from(response.delta, 'base64');
              const pcm16_8khz = downsample24to8(pcm16_24khz);
              const mulaw_8khz = pcm16ToMulaw(pcm16_8khz);

              const audioMessage = {
                event: 'media',
                streamSid: streamSid,
                media: { payload: mulaw_8khz.toString('base64') }
              };
              connection.send(JSON.stringify(audioMessage));
            }
            break;

          case 'response.audio.done':
            console.log('ğŸµ Ses yanÄ±tÄ± tamamlandÄ±');
            break;

          case 'response.done':
            isAssistantSpeaking = false;
            audioChunkCount = 0;
            currentResponseId = null;
            pendingResponseCreate = false;
            console.log('âœ… Eda konuÅŸmayÄ± bitirdi');
            break;

          case 'input_audio_buffer.speech_started':
            isUserSpeaking = true;
            console.log('ğŸ™ï¸ KullanÄ±cÄ± konuÅŸmaya baÅŸladÄ±');
            
            if (isAssistantSpeaking) {
              clearTimeout(bargeInTimer);
              userSpeakingSince = Date.now();
              
              // Interrupt logic - biraz gecikme ekle
              bargeInTimer = setTimeout(() => {
                const dur = Date.now() - (userSpeakingSince || Date.now());
                if (dur >= BARGE_IN_MIN_MS && isAssistantSpeaking) {
                  handleUserInterruption();
                }
              }, BARGE_IN_GRACE_MS);
            }
            break;

          case 'input_audio_buffer.speech_stopped': {
            isUserSpeaking = false;
            console.log('ğŸ”‡ KullanÄ±cÄ± konuÅŸmayÄ± bitirdi');

            // Sessizlikte kÃ¼Ã§Ã¼k bekleme + commit yalnÄ±zca yeterli audio varsa
            const doCommit = () => {
              console.log(`ğŸ’­ Commit kontrolÃ¼: uncommittedMs=${uncommittedMs}, min=${MIN_COMMIT_MS}`);
              
              if (uncommittedMs >= MIN_COMMIT_MS) {
                console.log('ğŸ“ Audio buffer commit ediliyor...');
                openAiWs.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
                lastCommitAt = Date.now();
                uncommittedMs = 0;
                
                // Commit'ten sonra response iste
                setTimeout(() => {
                  safeCreateResponse();
                }, 100);
              } else {
                console.log('âš ï¸ Yeterli audio yok, commit atlanÄ±yor');
              }
            };

            setTimeout(doCommit, POST_SILENCE_DEBOUNCE_MS);
            clearTimeout(bargeInTimer);
            userSpeakingSince = null;
            break;
          }

          case 'error':
            console.error('âŒ OpenAI HatasÄ±:', response.error);
            
            // Ã–zel hata handling
            if (response.error?.code === 'input_audio_buffer_commit_empty') {
              console.log('ğŸ”§ Buffer boÅŸ hatasÄ± - uncommittedMs sÄ±fÄ±rlanÄ±yor');
              uncommittedMs = 0;
            }
            
            if (response.error?.code === 'conversation_already_has_active_response') {
              console.log('ğŸ”§ Aktif response var - flag sÄ±fÄ±rlanÄ±yor');
              pendingResponseCreate = false;
            }
            break;
        }
      } catch (error) {
        console.error('âŒ OpenAI mesaj iÅŸleme hatasÄ±:', error);
      }
    });

    openAiWs.on('error', (error) => {
      console.error('âŒ OpenAI WebSocket hatasÄ±:', error);
    });

    openAiWs.on('close', () => {
      console.log('ğŸ”Œ OpenAI baÄŸlantÄ±sÄ± kapandÄ±');
    });

    // ==================== TWILIO EVENTS ====================

    connection.on('message', (message) => {
      try {
        const data = JSON.parse(message);

        switch (data.event) {
          case 'start': {
            streamSid = data.start.streamSid;
            
            // CustomParameters handling - DÃœZELT: safely handle
            let params = {};
            try {
              if (data.start.customParameters && Array.isArray(data.start.customParameters)) {
                params = data.start.customParameters.reduce((acc, p) => {
                  if (p && p.name && p.value) {
                    acc[p.name] = p.value;
                  }
                  return acc;
                }, {});
              }
            } catch (err) {
              console.warn('âš ï¸ CustomParameters parse hatasÄ±:', err);
            }
            
            currentCallerNumber = params.from || data.start?.from || 'Bilinmiyor';
            console.log('ğŸ“ Twilio stream baÅŸladÄ±:', streamSid);
            console.log('ğŸ“Š Arama detaylarÄ±:', {
              callSid: params.callSid || data.start?.callSid || 'N/A',
              from: currentCallerNumber,
              to: params.to || data.start?.to || 'Bilinmiyor'
            });
            break;
          }

          case 'media': {
            latestMediaTimestamp = data.media.timestamp;
            if (!(openAiWs.readyState === WebSocket.OPEN && sessionConfigured)) break;

            const now = Date.now();
            const payloadB64 = data.media.payload;
            const ulawBuf = Buffer.from(payloadB64, 'base64');
            const pcm16 = mulawToPcm16(ulawBuf);
            const levelDb = rmsDbfs(pcm16);

            // prebuffer tut
            preBuffer.push({ payload: payloadB64, ts: now });
            const cutoff = now - PREBUFFER_MS;
            while (preBuffer.length && preBuffer[0].ts < cutoff) preBuffer.shift();

            // gate kararlarÄ±
            if (levelDb >= NOISE_GATE_DBFS) {
              if (!gateCandidateSince) gateCandidateSince = now;
              lastLoudAt = now;
              
              if (!gateOpen && now - gateCandidateSince >= NOISE_GATE_OPEN_MS) {
                gateOpen = true;
                if (DEBUG_AUDIO) console.log(`ğŸšª Noise gate OPEN @ ${levelDb.toFixed(1)} dBFS`);

                // prebuffer'Ä± gÃ¶nder ve uncommitted say
                for (const f of preBuffer) {
                  openAiWs.send(JSON.stringify({ type: 'input_audio_buffer.append', audio: f.payload }));
                  uncommittedMs += 20; // Twilio frame â‰ˆ20ms
                }
              }
            } else {
              gateCandidateSince = null;
            }

            if (gateOpen) {
              openAiWs.send(JSON.stringify({ type: 'input_audio_buffer.append', audio: payloadB64 }));
              uncommittedMs += 20;

              // uzun sessizlikte kapat
              if (now - lastLoudAt > NOISE_GATE_HANG_MS) {
                gateOpen = false;
                preBuffer = [];
                if (DEBUG_AUDIO) console.log('ğŸšª Noise gate CLOSE (hang timeout)');
              }
            }
            break;
          }

          case 'mark':
            if (DEBUG_AUDIO) console.log(`âœ“ Mark alÄ±ndÄ±: ${data.mark?.name}`);
            break;

          case 'stop':
            console.log('ğŸ“ Ã‡aÄŸrÄ± sonlandÄ±');
            // KapanÄ±rken varsa commit et
            if (openAiWs.readyState === WebSocket.OPEN) {
              if (uncommittedMs >= MIN_COMMIT_MS) {
                openAiWs.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
              }
              openAiWs.close();
            }
            break;

          default:
            break;
        }
      } catch (error) {
        console.error('âŒ Twilio mesaj iÅŸleme hatasÄ±:', error);
      }
    });

    connection.on('close', () => {
      console.log('ğŸ‘‹ Twilio baÄŸlantÄ±sÄ± kapandÄ±');
      if (openAiWs.readyState === WebSocket.OPEN) openAiWs.close();
    });

    connection.on('error', (error) => {
      console.error('âŒ Twilio WebSocket hatasÄ±:', error);
    });
  });
});

// ==================== START SERVER ====================

fastify.listen({ port: PORT, host: '0.0.0.0' }, (err) => {
  if (err) {
    console.error('âŒ Sunucu baÅŸlatÄ±lamadÄ±:', err);
    process.exit(1);
  }
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ‰ EDA SESLÄ° ASÄ°STAN v3.2.1 HAZIR! ğŸ‰              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“ Port: ${PORT}                                           â•‘
â•‘  ğŸ¤ Ses: ${VOICE}                                           â•‘
â•‘  ğŸ”§ Noise Gate: ${NOISE_GATE_DBFS} dBFS | ${NOISE_GATE_OPEN_MS}ms open | ${NOISE_GATE_HANG_MS}ms hang
â•‘  ğŸ”§ Prebuffer: ${PREBUFFER_MS}ms | MinCommit: ${MIN_COMMIT_MS}ms
â•‘  ğŸ”§ Barge-in: â‰¥${MIN_ASSISTANT_SPEAK_MS}ms asistan sÃ¼resi ÅŸartÄ±
â•‘  ğŸ”§ YanÄ±t token: intent-based (60/120/220)
â•‘  âœ… Interrupt handling ve audio buffer sorunlarÄ± dÃ¼zeltildi!â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  `);
});
